{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "%pip install pymupdf\n",
    "%pip install pinecone\n",
    "%pip install groq\n",
    "%pip install --upgrade langchain\n",
    "%pip install langchain-community\n",
    "%pip install pypdf\n",
    "%pip install langchain-community\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from groq import Groq\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Selección del device\n",
    "device =  'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(device) # Expected: ‘cuda’ if Linux else ‘mps’ if MacOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Carga del CV y obtención de los embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "# Leer documentos\n",
    "def read_doc(directory):\n",
    "    file_loader=PyPDFDirectoryLoader(directory)\n",
    "    documents = file_loader.load()\n",
    "    return documents\n",
    "\n",
    "doc=read_doc(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from docx import Document\n",
    "\n",
    "# Abre el archivo .docx y lo devuelve como texto\n",
    "def open_content(path):\n",
    "    \n",
    "    # Abrir el archivo .docx\n",
    "    doc = Document(path)\n",
    "    \n",
    "    # Extraer todo el texto del documento\n",
    "    content = ''\n",
    "    for para in doc.paragraphs:\n",
    "        content += para.text + '\\n'  # Concatenar cada párrafo con salto de línea\n",
    "    \n",
    "    return content\n",
    "\n",
    "# Leer y procesar el contenido para añadirlo a la colección en Chroma\n",
    "doc = open_content('Silva_Victor_CV.docx')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Silva_Victor_CV.pdf', 'page': 0}, page_content='VíctorDavidSilvawww .link edin.com/in/vict or-da vid-silv a Mendoza,Argentina•vic.silva.1994@gmail.com•+5492616104445ExperienceIMPSA Mendoza,ArgentinaIAEngineer July2024–Present● Developingafaultdetectionsystemforsolarpanelsusingartificialintelligence.Thermalimagesarecollectedbyadrone,andmalfunctionsareidentifiedandcategorizedbytypeusingcomputervision.\\nAutomationEngineer November 2021–Present● DevelopedanddesignedaProgrammableLogicController(PLC)programandHuman-MachineInterface(HMI)forabutterflyvalveatahydraulicpowerplant.● DevelopedanddesignedProgrammableLogicController(PLC)program,Human-MachineInterface(HMI)andSupervisoryControlandDataAcquisition(SCADA)systemforalevelluffingcranesystemusingTIAPortal,fortheArgentinaNavy.● DevelopedanddesignedProgrammableLogicController(PLC)programandHuman-MachineInterface(HMI)foranoverheadcranesystemusingTIAPortal,foranuclearpowerplant.● Resolvedissuesinpowerplantsthroughremoteinterventions,offeringefficientsolutionstochallengesassociatedwithdatabasesandSCADAsystems.\\nEducationUniversidaddeBuenosAires BuenosAires,ArgentinaArtificialIntelligenceSpecialist October2023-Present\\nUniversidadNacionaldeCuyo Mendoza,ArgentinaMechatronicsEngineer November2022● Recognitionforacademicperformance(2022).● 1stplace-ContestDesignandDevelopmentofRobotsforProductiveorServiceApplications-Preliminarydesign(2021).● 3rdplace-\"EmprendeU,PremioFUNC2021alaInnovación\"-Awardstoinnovation(2021).● 1stplace-ProcessSimulateinternationalchallenge(2021).● OneyearofformalcourseworkinArtificialIntelligence.\\nCapitánDanielManzotti Mendoza,ArgentinaElectronicsTechnician December2012● Nationalflagbearer(thefirstintheclass).\\nTechnicalSkillsDataandSoftwareEngineering: IndustrialAutomation\\n● Python(Numpy,Pandas,Scikit-Learn,Matplotlib,SeaBorn)● MachineLearning(SVM,DecisionTrees,RandomForest)● DeepLearning(CNN,RNN,Encoder-Decoder,TransferLearning)● Evolutionaryalgorithm● Timeseriesanalysis\\n● ComputerVision(OpenCV,Pytorch,PytorchLightning)● NaturalLanguageProcessing(Tensorflow,Keras)● Diffusionmodels● AIGenerativetools● LabelStudio● SQL● Java\\n● PLCprogramming● HMIdesign● SCADAdevelopment● TIAPortal(Siemens)● Schneider● IndusoftSCADA● Matlab● AtmelStudio(AVR)andArduino● C/C++\\nLanguage:Spanish(native),English(B2).')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "page_content='VíctorDavidSilvawww .link edin.com/in/vict or-da vid-silv a Mendoza,Argentina•vic.silva.1994@gmail.com•+5492616104445ExperienceIMPSA Mendoza,ArgentinaIAEngineer July2024–Present● Developingafaultdetectionsystemforsolarpanelsusingartificialintelligence.Thermalimagesarecollectedbyadrone,andmalfunctionsareidentifiedandcategorizedbytypeusingcomputervision.\n",
      "AutomationEngineer November 2021–Present● DevelopedanddesignedaProgrammableLogicController(PLC)programandHuman-MachineInterface(HMI)forabutterflyvalveatahydraulicpowerplant.● DevelopedanddesignedProgrammableLogicController(PLC)program,Human-MachineInterface(HMI)andSupervisoryControlandDataAcquisition(SCADA)systemforalevelluffingcranesystemusingTIAPortal,fortheArgentinaNavy.● DevelopedanddesignedProgrammableLogicController(PLC)programandHuman-MachineInterface(HMI)foranoverheadcranesystemusingTIAPortal,foranuclearpowerplant.● Resolvedissuesinpowerplantsthroughremoteinterventions,offeringefficientsolutionstochallengesassociatedwithdatabasesandSCADAsystems.\n",
      "EducationUniversidaddeBuenosAires BuenosAires,ArgentinaArtificialIntelligenceSpecialist October2023-Present\n",
      "UniversidadNacionaldeCuyo Mendoza,ArgentinaMechatronicsEngineer November2022● Recognitionforacademicperformance(2022).● 1stplace-ContestDesignandDevelopmentofRobotsforProductiveorServiceApplications-Preliminarydesign(2021).● 3rdplace-\"EmprendeU,PremioFUNC2021alaInnovación\"-Awardstoinnovation(2021).● 1stplace-ProcessSimulateinternationalchallenge(2021).● OneyearofformalcourseworkinArtificialIntelligence.\n",
      "CapitánDanielManzotti Mendoza,ArgentinaElectronicsTechnician December2012● Nationalflagbearer(thefirstintheclass).\n",
      "TechnicalSkillsDataandSoftwareEngineering: IndustrialAutomation\n",
      "● Python(Numpy,Pandas,Scikit-Learn,Matplotlib,SeaBorn)● MachineLearning(SVM,DecisionTrees,RandomForest)● DeepLearning(CNN,RNN,Encoder-Decoder,TransferLearning)● Evolutionaryalgorithm● Timeseriesanalysis\n",
      "● ComputerVision(OpenCV,Pytorch,PytorchLightning)● NaturalLanguageProcessing(Tensorflow,Keras)● Diffusionmodels● AIGenerativetools● LabelStudio● SQL● Java\n",
      "● PLCprogramming● HMIdesign● SCADAdevelopment● TIAPortal(Siemens)● Schneider● IndusoftSCADA● Matlab● AtmelStudio(AVR)andArduino● C/C++\n",
      "Language:Spanish(native),English(B2).' metadata={'source': 'Silva_Victor_CV.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(type(doc))  # Verifica el tipo de `doc`\n",
    "print(doc[0])     # Muestra el primer elemento para entender su estructura\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "def chunk_documents(documents, chunk_size=50, chunk_overlap=15):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\" \",#[\"\\n\", \" \"],  # Divide por líneas primero\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = []\n",
    "    for doc in documents:\n",
    "        # Divide el contenido del texto en fragmentos\n",
    "        for chunk in text_splitter.split_text(doc.page_content): \n",
    "            chunks.append({\n",
    "                \"text\": chunk,\n",
    "                \"metadata\": doc.metadata #  # Mantén la fuente original\n",
    "            })\n",
    "    return chunks\n",
    "\n",
    "# Divide los documentos en fragmentos\n",
    "chunked_docs = chunk_documents(doc)\n",
    "\n",
    "# Verifica el número de fragmentos generados\n",
    "print(f\"Total de fragmentos generados: {len(chunked_docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_docs[8]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documentos en la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Configurar clave de API de Pinecone\n",
    "PINECONE_API_KEY = os.getenv(\"pinecone_api_key\")\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
    "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
    "\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)\n",
    "\n",
    "index_name = 'cv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Crear índice si no existe\n",
    "existing_indexes = [\n",
    "    index_info[\"name\"] for index_info in pc.list_indexes()\n",
    "]\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in existing_indexes:\n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=384,  # dimensionality of minilm\n",
    "        metric='cosine',\n",
    "        spec=spec\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del modelo de embedding\n",
    "embed_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Leer documentos\n",
    "def read_doc(directory):\n",
    "    file_loader = PyPDFDirectoryLoader(directory)\n",
    "    documents = file_loader.load()\n",
    "    return documents\n",
    "\n",
    "# Procesar documentos y generar embeddings\n",
    "def process_docs(documents):\n",
    "    texts = [doc['text'] for doc in documents]\n",
    "    embeddings = embed_model.encode(texts, convert_to_tensor=False, show_progress_bar=True)\n",
    "    return texts, embeddings\n",
    "\n",
    "\n",
    "# Leer y procesar documentos\n",
    "#directory = \"./\"  # Directorio donde está tu CV en formato PDF\n",
    "#documents = read_doc(directory)\n",
    "texts, embeddings = process_docs(chunked_docs)\n",
    "\n",
    "# Subir los embeddings a Pinecone\n",
    "ids = [f\"doc_{i}\" for i in range(len(texts))]  # Crear IDs únicos para los documentos\n",
    "vectors = [{\"id\": doc_id, \"values\": emb, \"metadata\": {\"text\": text}}\n",
    "           for doc_id, emb, text in zip(ids, embeddings, texts)]\n",
    "\n",
    "# Subir los vectores al índice en lotes\n",
    "batch_size = 5\n",
    "for i in tqdm(range(0, len(vectors), batch_size)):\n",
    "    batch = vectors[i:i + batch_size]\n",
    "    index.upsert(batch)\n",
    "\n",
    "# Ver estadísticas del índice\n",
    "stats = index.describe_index_stats()\n",
    "print(stats)\n",
    "\n",
    "print(f\"Generados {len(embeddings)} embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Human machine interface\"\n",
    "\n",
    "# create the query vector\n",
    "xq = embed_model.encode(query).tolist()\n",
    "\n",
    "# now query\n",
    "xc = index.query(vector=xq, top_k=5, include_metadata=True)\n",
    "xc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Implementación de un chatbot simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "# Carga la clave de API de GROQ desde las variables de entorno\n",
    "GROQ_API_KEY = os.getenv(\"groq_api_key\")\n",
    "\n",
    "# Crea el cliente de GROQ\n",
    "client = Groq(\n",
    "    api_key=GROQ_API_KEY,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "# Configurar Groq\n",
    "GROQ_API_KEY = os.getenv(\"groq_api_key\")\n",
    "groq_client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "def query_pinecone(index, query, top_k=5):\n",
    "    \"\"\"\n",
    "    Consulta Pinecone y devuelve los documentos más relevantes.\n",
    "    \"\"\"\n",
    "    # Crear el vector de la consulta\n",
    "    query_vector = embed_model.encode(query).tolist()\n",
    "    \n",
    "    # Consultar Pinecone\n",
    "    results = index.query(vector=query_vector, top_k=top_k, include_metadata=True)\n",
    "    return results[\"matches\"]\n",
    "\n",
    "def create_prompt(query, pinecone_matches):\n",
    "    \"\"\"\n",
    "    Crea un prompt para Groq utilizando la consulta y los documentos relevantes.\n",
    "    \"\"\"\n",
    "    context = \"\\n\".join([match[\"metadata\"][\"text\"] for match in pinecone_matches])\n",
    "    prompt = f\"\"\"\n",
    "    Contexto relevante:\n",
    "    {context}\n",
    "\n",
    "    Pregunta:\n",
    "    {query}\n",
    "\n",
    "    Responde con información relevante al contexto y de forma concisa:\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "def ask_groq(client, prompt, model=\"llama3-8b-8192\"):\n",
    "    \"\"\"\n",
    "    Envía el prompt a Groq y devuelve la respuesta.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=model\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Flujo principal\n",
    "query = \"Human machine interface\" #\"Human machine interface\"\n",
    "top_k = 5\n",
    "\n",
    "# 1. Consultar Pinecone\n",
    "matches = query_pinecone(index, query, top_k=top_k)\n",
    "\n",
    "# 2. Crear el prompt para Groq\n",
    "prompt = create_prompt(query, matches)\n",
    "\n",
    "# 3. Enviar el prompt a Groq y obtener la respuesta\n",
    "response = ask_groq(groq_client, prompt)\n",
    "\n",
    "print(\"Respuesta de Groq:\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "# Inicializa el historial de conversación en el estado de la sesión\n",
    "if \"conversation_history\" not in st.session_state:\n",
    "    st.session_state.conversation_history = []\n",
    "\n",
    "def generate_response(input_text):\n",
    "    # Agrega el mensaje del usuario al historial de conversación\n",
    "    st.session_state.conversation_history.append({\"role\": \"user\", \"content\": input_text})\n",
    "\n",
    "    # Genera la respuesta del chatbot utilizando el modelo LLaMA 3 y el historial de la conversación\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=st.session_state.conversation_history,\n",
    "        model=\"llama3-8b-8192\",\n",
    "    )\n",
    "    response = chat_completion.choices[0].message.content\n",
    "\n",
    "    # Agrega la respuesta del chatbot al historial de conversación\n",
    "    st.session_state.conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "    return response\n",
    "\n",
    "# Configuración de la interfaz de Streamlit\n",
    "st.title(\"Chatbot con LLaMA 3\")\n",
    "st.subheader(\"¡Hazme una pregunta!\")\n",
    "\n",
    "user_input = st.text_input(\"Usuario:\", \"\")\n",
    "\n",
    "if user_input:\n",
    "    response = generate_response(user_input)\n",
    "    st.write(f\"**Chatbot**: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Widgets para la interacción\n",
    "input_box = widgets.Text(\n",
    "    placeholder='Introduce tu pregunta...',\n",
    "    description='Pregunta:',\n",
    "    continuous_update=False  # Asegúrate de deshabilitar actualizaciones continuas\n",
    ")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def handle_input(change):\n",
    "    with output_area:\n",
    "        output_area.clear_output()  # Limpiar salida previa\n",
    "        query = input_box.value\n",
    "        if query.strip():  # Evitar procesar entradas vacías\n",
    "            # Aquí debes integrar las funciones query_pinecone, create_prompt, y ask_groq\n",
    "            # Esto es un ejemplo básico para mostrar cómo debería verse\n",
    "            print(f\"Consulta procesada: {query}\")\n",
    "            # Ejemplo de respuesta ficticia\n",
    "            print(\"Respuesta: Esto es un ejemplo de respuesta generada.\")\n",
    "        else:\n",
    "            print(\"Por favor, introduce una pregunta válida.\")\n",
    "\n",
    "# Usar observe para detectar cambios en el valor del campo de texto\n",
    "input_box.observe(handle_input, names='value')\n",
    "\n",
    "# Mostrar widgets en el notebook\n",
    "display(input_box, output_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmsiagenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
